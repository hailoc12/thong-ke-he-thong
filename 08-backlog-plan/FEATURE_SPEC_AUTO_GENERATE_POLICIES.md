# Feature Spec: T·ª± ƒë·ªông T·∫°o Gi·∫£i Ph√°p (Auto-Generate Improvement Policies)

**Version:** 2.0
**Date:** 2026-02-06
**Status:** In Development

---

## üéØ M·ª•c ƒê√≠ch

T·ª± ƒë·ªông ph√¢n t√≠ch c√°c ph·∫£n h·ªìi ti√™u c·ª±c t·ª´ user v·ªÅ AI Assistant v√† t·∫°o ra **context prompts** (improvement policies) ƒë·ªÉ inject v√†o system prompt, gi√∫p AI Assistant:
1. Hi·ªÉu r√µ h∆°n v·ªÅ database schema v√† domain knowledge
2. Generate SQL queries ch√≠nh x√°c h∆°n
3. Tr·∫£ l·ªùi ƒë√∫ng c√°c c√¢u h·ªèi t∆∞∆°ng t·ª± trong t∆∞∆°ng lai

**Key Insight:** Policies kh√¥ng ph·∫£i l√† rules ƒë∆°n thu·∫ßn, m√† l√† **context information** v·ªÅ database/domain m√† AI c·∫ßn bi·∫øt ƒë·ªÉ map user questions ‚Üí correct SQL queries.

---

## üìä User Flow

### Flow 1: Automatic Policy Generation (Primary)

```
User asks question
    ‚Üì
AI Assistant answers (with steps, SQL, results)
    ‚Üì
User rates: üëé Negative
    ‚Üì
User adds feedback text explaining the issue
    ‚Üì
User clicks "G·ª≠i feedback"
    ‚Üì
[AUTOMATIC TRIGGER]
    ‚Üì
System checks: Has this feedback already generated policy?
    ‚îú‚îÄ Yes ‚Üí Skip generation (feedback.has_policy = True)
    ‚îî‚îÄ No ‚Üí Generate policy immediately
        ‚Üì
        Backend analyzes:
        - User question
        - User feedback text
        - AI response steps
        - SQL queries executed
        - Query results
        - Error/mismatch details
        ‚Üì
        Extract key insight:
        "What database/domain knowledge is missing?"
        ‚Üì
        Generate policy prompt:
        Category, Rule, Priority, Rationale, Examples
        ‚Üì
        Save policy & mark feedback.has_policy = True
        ‚Üì
        Return success to user
```

**User Experience:**
- User submits negative feedback
- Sees message: "‚úÖ ƒê√£ ghi nh·∫≠n ph·∫£n h·ªìi v√† t·∫°o gi·∫£i ph√°p t·ª± ƒë·ªông"
- Policy immediately active for future queries

---

### Flow 2: Manual Regeneration (Admin/Leader Only)

**Trigger:** User clicks button "T·ª± ƒë·ªông t·∫°o gi·∫£i ph√°p" trong trang "Tinh ch·ªânh Tr·ª£ l√Ω A.I"

**Use Cases:**
1. Batch regenerate all policies from scratch (improve algorithm)
2. Regenerate for specific feedbacks that failed auto-generation
3. Update existing policies with better analysis

```
Leader/Admin visits: /ai-feedback page
    ‚Üì
Clicks "T·ª± ƒë·ªông t·∫°o gi·∫£i ph√°p" button
    ‚Üì
System shows confirm modal:
"T·∫°o l·∫°i policies t·ª´ T·∫§T C·∫¢ feedbacks ti√™u c·ª±c?
Policies hi·ªán t·∫°i s·∫Ω b·ªã ghi ƒë√®."
    ‚Üì
User confirms: "C√≥, t·∫°o l·∫°i"
    ‚Üì
Backend regenerates ALL policies:
    - Analyze all negative feedbacks (even if has_policy=True)
    - Re-extract insights with latest algorithm
    - Overwrite existing policies
    - Mark all as analyzed
    ‚Üì
Return: "‚úÖ ƒê√£ t·∫°o l·∫°i X policies t·ª´ Y feedbacks"
```

---

## üèóÔ∏è Technical Architecture

### 1. Data Model

#### AIResponseFeedback
```python
class AIResponseFeedback(models.Model):
    query = models.TextField()  # User's question
    mode = models.CharField(choices=['quick', 'deep'])
    response_data = models.JSONField()  # Full AI response with steps
    conversation_context = models.JSONField(null=True)
    rating = models.CharField(choices=['positive', 'negative'])
    feedback_text = models.TextField(blank=True)

    # Policy tracking
    has_policy = models.BooleanField(default=False)  # NEW FIELD
    policy_generated_at = models.DateTimeField(null=True)

    created_at = models.DateTimeField(auto_now_add=True)
    user = models.ForeignKey(User)
```

#### response_data Structure
```json
{
  "question": "Bao nhi√™u h·ªá th·ªëng c√≥ tr√™n 1.000 user?",
  "answer": "0 h·ªá th·ªëng",  // WRONG ANSWER
  "steps": [
    {
      "action": "analyze_question",
      "detail": "Ph√¢n t√≠ch c√¢u h·ªèi ƒë·ªÉ x√°c ƒë·ªãnh intent",
      "result": "COUNT systems WHERE user_count > 1000"
    },
    {
      "action": "execute_query",
      "sql": "SELECT COUNT(*) FROM systems WHERE user_field > 1000",
      "result": 0,
      "execution_time": "0.05s"
    },
    {
      "action": "format_answer",
      "result": "C√≥ 0 h·ªá th·ªëng c√≥ tr√™n 1.000 user"
    }
  ],
  "queries": [
    {
      "sql": "SELECT COUNT(*) FROM systems WHERE user_field > 1000",
      "results": [],
      "row_count": 0
    }
  ],
  "metadata": {
    "model": "gpt-4",
    "execution_time": "2.3s",
    "confidence": 0.85
  }
}
```

---

### 2. Policy Generation Algorithm

#### Input Data for AI Analysis
```python
def generate_policy_from_feedback(feedback: AIResponseFeedback):
    """
    Analyze negative feedback and generate improvement policy.

    The AI needs FULL CONTEXT to understand what went wrong:
    - What user asked
    - What AI did (steps, SQL queries)
    - What results were returned
    - Why user said it's wrong (feedback_text)
    """

    context = {
        # User's question
        "question": feedback.query,

        # User's explanation of the problem
        "feedback": feedback.feedback_text,

        # What AI did wrong
        "ai_response": {
            "answer": feedback.response_data.get("answer"),
            "steps": feedback.response_data.get("steps", []),
            "sql_queries": feedback.response_data.get("queries", []),
        },

        # Database schema (if available)
        "schema_info": get_relevant_schema_for_question(feedback.query),

        # Previous similar issues (if any)
        "similar_feedbacks": find_similar_feedbacks(feedback),

        # IMPORTANT: Existing policies to avoid duplicates
        "existing_policies": get_active_policies(),
        "current_system_prompt": build_system_prompt_with_policies(),
    }

    # Send to AI for analysis
    policy = ai_analyze_and_generate_policy(context)

    return policy
```

#### AI Analysis Prompt Template
```
You are analyzing why an AI Assistant gave a wrong answer.

QUESTION:
{question}

AI'S WRONG ANSWER:
{answer}

STEPS AI TOOK:
{steps}

SQL QUERIES EXECUTED:
{sql_queries}

QUERY RESULTS:
{results}

USER'S FEEDBACK:
{feedback_text}

DATABASE SCHEMA (relevant tables):
{schema_info}

EXISTING POLICIES (already in system prompt):
{existing_policies}

IMPORTANT: Check existing policies FIRST to avoid generating duplicates.
Only generate a NEW policy if:
1. This issue is NOT already covered by existing policies
2. The new policy adds DIFFERENT knowledge/context
3. The new policy complements (not overlaps with) existing ones

TASK:
Identify the ROOT CAUSE of the wrong answer. What DATABASE/DOMAIN KNOWLEDGE
was missing that caused the AI to generate incorrect SQL or misinterpret the question?

EXTRACT:
1. **Category**: accuracy | clarity | completeness | schema_mapping | domain_knowledge
2. **Missing Knowledge**: What specific information about the database/domain is needed?
3. **Correct Mapping**: What is the correct way to map user's question to database fields?
4. **Policy Rule**: Write a clear instruction that tells future AI queries how to handle similar questions
5. **Priority**: high | medium | low (based on how common this issue is)
6. **Rationale**: Brief explanation of why this policy is needed
7. **Examples**: 2-3 example questions that this policy helps with

OUTPUT FORMAT (JSON):
{
  "category": "schema_mapping",
  "rule": "Khi user h·ªèi v·ªÅ 'X user' ho·∫∑c 'X ng∆∞·ªùi d√πng', map to column 'total_users' in table 'systems', NOT 'user_field' or 'user_count'",
  "priority": "high",
  "rationale": "Users often ask about user counts but AI was querying wrong column name. Correct column is 'total_users'.",
  "examples": [
    "C√≥ bao nhi√™u h·ªá th·ªëng tr√™n 1.000 user?",
    "H·ªá th·ªëng n√†o c√≥ nhi·ªÅu user nh·∫•t?",
    "Top 5 h·ªá th·ªëng theo s·ªë ng∆∞·ªùi d√πng"
  ],
  "missing_knowledge": "Column name for user count is 'total_users', not 'user_field'",
  "correct_mapping": "user/ng∆∞·ªùi d√πng ‚Üí total_users column"
}

IF DUPLICATE (policy already exists covering this):
{
  "skip": true,
  "reason": "Existing policy already covers this: [Policy #5] maps user questions to total_users column",
  "suggestion": "No new policy needed"
}
```

#### Example: Checking Existing Policies

**Scenario 1: New Issue (Should Generate)**
```
Existing Policies:
1. [schema_mapping] Map "user/ng∆∞·ªùi d√πng" ‚Üí total_users column
2. [schema_mapping] Map "nƒÉm tri·ªÉn khai" ‚Üí deployment_year column

New Feedback:
"AI tr·∫£ l·ªùi sai khi h·ªèi v·ªÅ 'h·ªá th·ªëng chuy·ªÉn ƒë·ªïi s·ªë'.
AI search t·∫•t c·∫£ systems, nh∆∞ng ƒë√∫ng ph·∫£i filter theo digital_transformation_level."

Analysis:
‚úÖ GENERATE NEW POLICY
- Issue: Domain knowledge about "chuy·ªÉn ƒë·ªïi s·ªë" mapping
- Not covered by existing policies (they only cover user & year mappings)
- New policy: Map "chuy·ªÉn ƒë·ªïi s·ªë" ‚Üí digital_transformation_level filter
```

**Scenario 2: Duplicate (Should Skip)**
```
Existing Policies:
1. [schema_mapping] Map "user/ng∆∞·ªùi d√πng" ‚Üí total_users column
   Example: "C√≥ bao nhi√™u h·ªá th·ªëng tr√™n 1.000 user?"

New Feedback:
"AI sai khi h·ªèi 'Top 5 h·ªá th·ªëng c√≥ nhi·ªÅu user nh·∫•t'. AI query user_field thay v√¨ total_users."

Analysis:
‚ùå SKIP - DUPLICATE
- Issue: Same as Policy #1 (user ‚Üí total_users mapping)
- Policy #1 already covers this exact mapping
- Action: Update evidence_count on Policy #1, don't create new policy
```

**Scenario 3: Complementary (Should Generate)**
```
Existing Policies:
1. [schema_mapping] Map "user" ‚Üí total_users column

New Feedback:
"AI tr·∫£ l·ªùi ƒë√∫ng s·ªë l∆∞·ª£ng user, nh∆∞ng kh√¥ng bi·∫øt distinguish gi·ªØa 'user active' vs 'total user'.
Khi h·ªèi v·ªÅ 'user ƒëang ho·∫°t ƒë·ªông', c·∫ßn filter th√™m is_active=True."

Analysis:
‚úÖ GENERATE NEW POLICY
- Issue: Distinction between active vs total users
- Complements Policy #1 (adds nuance, doesn't duplicate)
- New policy: When asking about "user ƒëang ho·∫°t ƒë·ªông/active", filter by is_active=True
```

---

### 3. API Endpoints

#### POST /api/ai-feedback/ (Submit Feedback)
```python
# Request
{
  "query": "Bao nhi√™u h·ªá th·ªëng c√≥ tr√™n 1.000 user?",
  "mode": "deep",
  "response_data": { ... },  # Full AI response with steps
  "rating": "negative",
  "feedback_text": "AI tr·∫£ l·ªùi sai! Th·ª±c t·∫ø c√≥ 3 h·ªá th·ªëng nh∆∞ng AI tr·∫£ l·ªùi 0. V·∫•n ƒë·ªÅ: AI query c·ªôt 'user_field' nh∆∞ng ƒë√∫ng l√† 'total_users'"
}

# Response
{
  "id": 123,
  "message": "ƒê√£ ghi nh·∫≠n ph·∫£n h·ªìi v√† t·∫°o gi·∫£i ph√°p t·ª± ƒë·ªông",
  "policy_generated": true,
  "policy_id": 456
}

# Backend Processing:
# 1. Save feedback
# 2. Check if has_policy = False
# 3. If False ‚Üí Auto-generate policy asynchronously
# 4. Mark has_policy = True after successful generation
```

#### POST /api/ai-feedback/regenerate_policies/ (Manual Regeneration)
```python
# Request (no body needed)

# Response
{
  "message": "ƒê√£ t·∫°o l·∫°i 15 policies t·ª´ 42 feedbacks ti√™u c·ª±c",
  "policies_count": 15,
  "feedbacks_analyzed": 42,
  "timestamp": "2026-02-06T16:30:00Z",
  "policies": [
    {
      "category": "schema_mapping",
      "rule": "...",
      "priority": "high",
      "evidence_count": 3
    },
    ...
  ]
}

# Backend Processing:
# 1. Fetch ALL negative feedbacks (ignore has_policy flag)
# 2. Group by similar issues
# 3. Generate/regenerate policies for each group
# 4. Overwrite existing policies
# 5. Update all feedback.has_policy = True
```

#### GET /api/ai-feedback/active_policies/ (Get Policies for Injection)
```python
# Response
{
  "active_policies": [
    {
      "category": "schema_mapping",
      "rule": "Khi user h·ªèi v·ªÅ 'X user', map to 'total_users' column",
      "priority": "high",
      "rationale": "...",
      "examples": [...]
    },
    ...
  ],
  "total_policies": 15,
  "active_count": 15,
  "last_updated": "2026-02-06T16:30:00Z"
}

# Used by AI Assistant to inject into system prompt
```

---

### 4. System Prompt Injection

**Where:** AI Assistant's system prompt (before each query)

**Format:**
```
You are an AI Assistant for querying the system database.

DATABASE SCHEMA:
[Standard schema documentation]

IMPROVEMENT GUIDELINES:
Based on previous user feedback, follow these guidelines to improve accuracy:

1. [schema_mapping] [HIGH] Khi user h·ªèi v·ªÅ "X user" ho·∫∑c "X ng∆∞·ªùi d√πng", map to column 'total_users' in table 'systems', NOT 'user_field' or 'user_count'
   Rationale: Users often ask about user counts but AI was querying wrong column. Correct column is 'total_users'.
   Examples: "C√≥ bao nhi√™u h·ªá th·ªëng tr√™n 1.000 user?", "H·ªá th·ªëng n√†o c√≥ nhi·ªÅu user nh·∫•t?"

2. [accuracy] [HIGH] When filtering by deployment year, use 'deployment_year' column which stores integer year (e.g., 2024), not 'deployment_date'
   Rationale: Multiple queries failed because AI used deployment_date for year filtering instead of the dedicated year column.

3. [domain_knowledge] [MEDIUM] "Chuy·ªÉn ƒë·ªïi s·ªë" means digital transformation - related to 'digital_transformation_level' field
   Rationale: Users asking about "h·ªá th·ªëng chuy·ªÉn ƒë·ªïi s·ªë" should map to digital_transformation_level, not a generic search.

[Total: 15 policies active]

Now answer the user's question following these guidelines.
```

---

## üîÑ Deduplication Logic

### Problem: Avoid duplicate policy generation for same feedback

**Solution: `has_policy` flag**

```python
# When submitting feedback
if feedback.rating == 'negative' and not feedback.has_policy:
    # Auto-generate policy
    generate_policy_async(feedback.id)
    feedback.has_policy = True
    feedback.policy_generated_at = now()
    feedback.save()
```

### Handling Edge Cases

**Case 1: Policy generation fails**
```python
try:
    policy = generate_policy(feedback)
    save_policy(policy)
    feedback.has_policy = True
except Exception as e:
    feedback.has_policy = False  # Allow retry
    log_error(e)
```

**Case 2: Manual regeneration**
```python
# Ignore has_policy flag, regenerate all
def manual_regenerate():
    for feedback in Feedback.objects.filter(rating='negative'):
        policy = generate_policy(feedback)  # Even if has_policy=True
        save_or_update_policy(policy)
        feedback.has_policy = True
        feedback.policy_generated_at = now()
        feedback.save()
```

**Case 3: Feedback updated by user**
```python
# If user edits their feedback_text
def update_feedback(feedback_id, new_text):
    feedback.feedback_text = new_text
    feedback.has_policy = False  # Allow regeneration with new info
    feedback.save()

    # Auto-regenerate with updated context
    generate_policy_async(feedback_id)
```

---

## üß™ Test Scenarios

### Test 1: Automatic Generation on Negative Feedback
```
1. User queries: "Bao nhi√™u h·ªá th·ªëng c√≥ tr√™n 1.000 user?"
2. AI answers: "0 h·ªá th·ªëng" (WRONG)
3. User rates: üëé
4. User adds feedback: "Sai! Th·ª±c t·∫ø c√≥ 3 h·ªá th·ªëng. AI query sai c·ªôt 'user_field', ƒë√∫ng l√† 'total_users'"
5. User clicks "G·ª≠i feedback"
6. VERIFY:
   - ‚úÖ Feedback saved with rating='negative'
   - ‚úÖ Policy auto-generated within 5 seconds
   - ‚úÖ feedback.has_policy = True
   - ‚úÖ Policy contains correct mapping: "user/ng∆∞·ªùi d√πng ‚Üí total_users"
   - ‚úÖ Policy priority = high (schema mapping issue)
7. Test same question again:
   - ‚úÖ AI should now query "total_users" column
   - ‚úÖ AI answers correctly: "3 h·ªá th·ªëng"
```

### Test 2: Manual Regeneration
```
1. Admin visits /ai-feedback page
2. Clicks "T·ª± ƒë·ªông t·∫°o gi·∫£i ph√°p"
3. Confirms action
4. VERIFY:
   - ‚úÖ Loading spinner shows
   - ‚úÖ Success message: "ƒê√£ t·∫°o l·∫°i X policies"
   - ‚úÖ Policy count updates
   - ‚úÖ ALL negative feedbacks have has_policy=True
   - ‚úÖ Policy quality improved (if algorithm updated)
```

### Test 3: Deduplication
```
1. User submits negative feedback #1
2. VERIFY: Policy generated, has_policy=True
3. User submits SAME negative feedback #2 (same issue)
4. VERIFY:
   - ‚úÖ No duplicate policy created
   - ‚úÖ Existing policy evidence_count++
5. Manual regeneration
6. VERIFY:
   - ‚úÖ Similar feedbacks grouped
   - ‚úÖ Single policy with multiple examples
```

---

## üìà Success Metrics

**Immediate (Technical):**
- ‚úÖ 100% of negative feedbacks generate policies automatically
- ‚úÖ < 5 seconds latency for policy generation
- ‚úÖ No duplicate policies for same issue
- ‚úÖ Policies contain correct schema mappings

**Short-term (1-2 weeks):**
- ‚úÖ AI accuracy improves by 30% on previously failed queries
- ‚úÖ Similar questions answered correctly after policy injection
- ‚úÖ Reduced negative feedback rate from 20% ‚Üí 10%

**Long-term (1-2 months):**
- ‚úÖ AI learns domain-specific mappings automatically
- ‚úÖ Self-improving system (more feedbacks ‚Üí better policies ‚Üí better answers)
- ‚úÖ 90% user satisfaction rate

---

## üöß Implementation Status

### ‚úÖ Completed
- [x] Basic feedback submission API
- [x] Manual policy regeneration button
- [x] Policy display in admin page
- [x] Policy injection into system prompt

### üî® In Progress
- [ ] Auto-generate on feedback submission
- [ ] `has_policy` flag and deduplication logic
- [ ] Rich context extraction (steps, SQL, results)
- [ ] AI analysis with full context
- [ ] Async policy generation

### üìã Todo
- [ ] Schema information integration
- [ ] Similar feedback detection
- [ ] Policy quality metrics
- [ ] A/B testing framework
- [ ] Policy effectiveness tracking

---

## üéì Example: Complete Flow

### User Query: "Bao nhi√™u h·ªá th·ªëng c√≥ tr√™n 1.000 user?"

**Step 1: AI attempts to answer (WRONG)**
```
AI executes:
SELECT COUNT(*) FROM systems WHERE user_field > 1000
Result: 0

AI responds: "C√≥ 0 h·ªá th·ªëng c√≥ tr√™n 1.000 ng∆∞·ªùi d√πng"
```

**Step 2: User rates negative + adds feedback**
```
Rating: üëé
Feedback: "C√¢u tr·∫£ l·ªùi sai! Th·ª±c t·∫ø c√≥ 3 h·ªá th·ªëng (HT VƒÉn b·∫£n: 5000 user,
C·ªïng th√¥ng tin: 3000 user, HT T√†i s·∫£n: 1500 user).

V·∫•n ƒë·ªÅ: AI query c·ªôt 'user_field' nh∆∞ng trong database, c·ªôt ƒë√∫ng l√† 'total_users'.

Y√™u c·∫ßu: Map 'user'/'ng∆∞·ªùi d√πng' ‚Üí 'total_users' column."
```

**Step 3: Auto-generate policy**
```
Backend receives feedback ‚Üí triggers policy generation

AI Analyzer input:
{
  "question": "Bao nhi√™u h·ªá th·ªëng c√≥ tr√™n 1.000 user?",
  "answer": "0 h·ªá th·ªëng",
  "steps": [...],
  "sql": "SELECT COUNT(*) FROM systems WHERE user_field > 1000",
  "result": 0,
  "feedback": "C√¢u tr·∫£ l·ªùi sai! ... Map 'user' ‚Üí 'total_users'",
  "schema": {
    "systems": {
      "columns": ["id", "name", "total_users", "user_field", ...]
    }
  }
}

AI Analyzer output:
{
  "category": "schema_mapping",
  "rule": "Khi user h·ªèi v·ªÅ 'X user' ho·∫∑c 'X ng∆∞·ªùi d√πng', lu√¥n map to column 'total_users' c·ªßa b·∫£ng systems. KH√îNG d√πng 'user_field' hay 'user_count'.",
  "priority": "high",
  "rationale": "Column name mismatch causing zero results. Correct column is 'total_users' which stores actual user count per system.",
  "examples": [
    "C√≥ bao nhi√™u h·ªá th·ªëng tr√™n 1.000 user?",
    "H·ªá th·ªëng n√†o c√≥ nhi·ªÅu user nh·∫•t?",
    "Top 5 systems theo s·ªë ng∆∞·ªùi d√πng"
  ],
  "missing_knowledge": "Correct column name for user count is 'total_users' in systems table",
  "correct_mapping": "user/ng∆∞·ªùi d√πng ‚Üí systems.total_users (NOT user_field)"
}

Save policy ‚Üí Mark feedback.has_policy = True
```

**Step 4: Next query uses the policy**
```
User asks again: "Bao nhi√™u h·ªá th·ªëng c√≥ tr√™n 1.000 user?"

AI's system prompt now includes:
"[schema_mapping] [HIGH] Khi user h·ªèi v·ªÅ 'X user', map to 'total_users' column in systems table"

AI executes:
SELECT COUNT(*) FROM systems WHERE total_users > 1000
Result: 3

AI responds: "C√≥ 3 h·ªá th·ªëng c√≥ tr√™n 1.000 ng∆∞·ªùi d√πng:
1. H·ªá th·ªëng qu·∫£n l√Ω vƒÉn b·∫£n - 5.000 user
2. C·ªïng th√¥ng tin ƒëi·ªán t·ª≠ - 3.000 user
3. H·ªá th·ªëng qu·∫£n l√Ω t√†i s·∫£n - 1.500 user"

‚úÖ CORRECT ANSWER!
```

---

## üîß Technical Notes

### Async Processing
```python
# Avoid blocking user feedback submission
@shared_task
def generate_policy_async(feedback_id):
    feedback = AIResponseFeedback.objects.get(id=feedback_id)

    if feedback.has_policy:
        return  # Already generated

    try:
        policy = generate_policy_from_feedback(feedback)
        save_policy(policy)

        feedback.has_policy = True
        feedback.policy_generated_at = timezone.now()
        feedback.save()

        logger.info(f"Auto-generated policy for feedback {feedback_id}")
    except Exception as e:
        logger.error(f"Failed to generate policy: {e}")
        # Retry later or notify admin
```

### Database Indexes
```sql
-- For fast lookup
CREATE INDEX idx_feedback_has_policy ON ai_response_feedback(has_policy);
CREATE INDEX idx_feedback_rating ON ai_response_feedback(rating);
CREATE INDEX idx_feedback_created ON ai_response_feedback(created_at);

-- For policy retrieval
CREATE INDEX idx_policy_priority ON improvement_policy(priority);
CREATE INDEX idx_policy_active ON improvement_policy(is_active);
```

---

**End of Spec**
