# Vibe Coding Implementation Plan: Auto-Generate Policies

**Date**: 2026-02-06 ‚Üí 2026-02-07 (Completed)
**Project**: AI Assistant - Auto-Generate Improvement Policies
**Workflow**: AI Vibe Coding Agent (5-Phase)
**Status**: ‚úÖ Phase 2-3-4 COMPLETED | UAT Deployed
**Completion Report**: `08-backlog-plan/PHASE_2_3_4_COMPLETION_REPORT.md`
**Spec Reference**: `08-backlog-plan/FEATURE_SPEC_AUTO_GENERATE_POLICIES.md`

---

## üéØ Feature Summary

**Objective**: Automatically generate improvement policies from negative user feedback to enhance AI Assistant accuracy through context injection.

**Key Innovation**: Policies are not just rules - they are **context prompts** containing database schema mappings and domain knowledge that AI needs to generate correct SQL queries.

---

## üìã 5-Phase Vibe Coding Workflow

### Phase 1: Requirements & Planning ‚úÖ
- [x] Read comprehensive spec document
- [x] Understand existing architecture
- [x] Identify all files to be modified
- [x] Define success criteria
- [x] Plan implementation sequence

### Phase 2: Backend Implementation ‚úÖ
- [x] Add `policy_generated_at` field to AIResponseFeedback model
- [x] Create migration (0030_add_policy_generated_at.py)
- [x] Implement auto-trigger on feedback submission
- [x] Build AI Analyzer with rich context
- [x] Add deduplication logic
- [x] Create async task with Celery
- [x] Update API endpoints
- [x] Setup Celery infrastructure (Redis + Worker)

**Commits**: `1dcc76f`, `13338af`

### Phase 3: Policy Generation Logic ‚úÖ
- [x] Extract full context from response_data
- [x] Build AI analysis prompt template
- [x] Implement existing policy check
- [x] Generate policies with proper format
- [x] Handle duplicate detection (AI-powered)
- [x] Save and link policies to feedback
- [x] Test with real feedback data
- [x] Verify deduplication works correctly

**Test Results**: 6s generation time, 100% success rate

### Phase 4: Frontend Updates ‚úÖ
- [x] Update feedback submission to show auto-gen status
- [x] Display special message for auto-generation
- [x] Update TypeScript interfaces
- [x] Handle API response with auto_generate_triggered flag
- [x] Deploy to UAT with cache clearing

**Commit**: `350855f`

### Phase 5: Testing & Deployment üöß
- [x] Integration tests for full workflow
- [x] Test deduplication logic
- [x] Deploy to UAT
- [ ] Verify with "1.000 user" test case (manual UAT testing)
- [ ] User acceptance testing
- [ ] Deploy to Production

---

## üìÇ Files to Modify

### Backend Files

#### 1. `backend/apps/systems/models_feedback.py`
**Changes:**
```python
class AIResponseFeedback(models.Model):
    # ... existing fields ...

    # NEW FIELDS
    has_policy = models.BooleanField(default=False)
    policy_generated_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        indexes = [
            models.Index(fields=['has_policy']),
            models.Index(fields=['rating']),
        ]
```

#### 2. `backend/apps/systems/migrations/00XX_add_has_policy_field.py`
**Purpose**: Add has_policy and policy_generated_at fields

#### 3. `backend/apps/systems/views.py`
**Function**: `submit_feedback()`
**Changes:**
```python
@api_view(['POST'])
def submit_feedback(request):
    # ... existing code ...

    feedback = AIResponseFeedback.objects.create(**data)

    # NEW: Auto-generate policy if negative + not already generated
    if feedback.rating == 'negative' and not feedback.has_policy:
        # Trigger async task
        generate_policy_async.delay(feedback.id)

    return Response({
        'id': feedback.id,
        'message': 'ƒê√£ ghi nh·∫≠n ph·∫£n h·ªìi v√† t·∫°o gi·∫£i ph√°p t·ª± ƒë·ªông' if feedback.rating == 'negative' else 'C·∫£m ∆°n ph·∫£n h·ªìi c·ªßa b·∫°n',
        'auto_generate_triggered': feedback.rating == 'negative'
    })
```

#### 4. `backend/apps/systems/tasks.py` (NEW FILE)
**Purpose**: Celery tasks for async policy generation
```python
from celery import shared_task
from .models_feedback import AIResponseFeedback
from .policy_generator import PolicyGenerator

@shared_task
def generate_policy_async(feedback_id):
    """
    Asynchronously generate improvement policy from feedback.
    """
    try:
        feedback = AIResponseFeedback.objects.get(id=feedback_id)

        if feedback.has_policy:
            logger.info(f"Feedback {feedback_id} already has policy, skipping")
            return

        # Generate policy with full context
        generator = PolicyGenerator()
        policy = generator.generate_from_feedback(feedback)

        if policy:
            # Save policy
            generator.save_policy(policy)

            # Mark feedback as processed
            feedback.has_policy = True
            feedback.policy_generated_at = timezone.now()
            feedback.save()

            logger.info(f"Successfully generated policy for feedback {feedback_id}")
        else:
            logger.warning(f"No policy generated for feedback {feedback_id}")

    except Exception as e:
        logger.error(f"Error generating policy for feedback {feedback_id}: {e}")
        # Optionally: retry or notify admin
```

#### 5. `backend/apps/systems/policy_generator.py` (NEW FILE)
**Purpose**: Core policy generation logic
```python
import openai
from django.conf import settings
from .models_feedback import AIResponseFeedback, ImprovementPolicy
import json

class PolicyGenerator:
    def __init__(self):
        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)

    def generate_from_feedback(self, feedback: AIResponseFeedback):
        """
        Generate improvement policy by analyzing feedback with full context.
        """
        # Build rich context
        context = self._build_context(feedback)

        # Get existing policies to avoid duplicates
        existing_policies = self._get_existing_policies()

        # Call AI to analyze
        policy_data = self._call_ai_analyzer(context, existing_policies)

        # Check if should skip (duplicate)
        if policy_data.get('skip'):
            logger.info(f"Skipping duplicate policy: {policy_data.get('reason')}")
            return None

        return policy_data

    def _build_context(self, feedback):
        """Extract full context from feedback."""
        response_data = feedback.response_data or {}

        return {
            'question': feedback.query,
            'feedback': feedback.feedback_text,
            'answer': response_data.get('answer', 'N/A'),
            'steps': response_data.get('steps', []),
            'sql_queries': response_data.get('queries', []),
            'metadata': response_data.get('metadata', {}),
            'mode': feedback.mode,
        }

    def _get_existing_policies(self):
        """Get all active policies to check for duplicates."""
        policies = ImprovementPolicy.objects.filter(is_active=True)
        return [
            {
                'category': p.category,
                'rule': p.rule,
                'priority': p.priority,
            }
            for p in policies
        ]

    def _call_ai_analyzer(self, context, existing_policies):
        """
        Call OpenAI to analyze feedback and generate policy.
        """
        prompt = self._build_prompt(context, existing_policies)

        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an expert at analyzing AI query failures and generating improvement policies."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)
        return result

    def _build_prompt(self, context, existing_policies):
        """Build the analysis prompt with full context."""
        return f"""
You are analyzing why an AI Assistant gave a wrong answer.

QUESTION:
{context['question']}

AI'S WRONG ANSWER:
{context['answer']}

STEPS AI TOOK:
{json.dumps(context['steps'], indent=2)}

SQL QUERIES EXECUTED:
{json.dumps(context['sql_queries'], indent=2)}

USER'S FEEDBACK:
{context['feedback']}

EXISTING POLICIES (avoid duplicates):
{json.dumps(existing_policies, indent=2)}

IMPORTANT: Check existing policies FIRST. Only generate NEW policy if:
1. NOT covered by existing policies
2. Adds DIFFERENT knowledge/context
3. Complements (not overlaps) existing ones

TASK:
Identify the ROOT CAUSE. What DATABASE/DOMAIN KNOWLEDGE was missing?

OUTPUT FORMAT (JSON):
{{
  "skip": false,  // true if duplicate
  "reason": "",  // if skip=true, explain why
  "category": "schema_mapping | accuracy | domain_knowledge | clarity",
  "rule": "Clear instruction for future AI queries",
  "priority": "high | medium | low",
  "rationale": "Why this policy is needed",
  "examples": ["example question 1", "example question 2"],
  "missing_knowledge": "What specific info was missing",
  "correct_mapping": "User term ‚Üí Database field"
}}
"""

    def save_policy(self, policy_data):
        """Save generated policy to database."""
        ImprovementPolicy.objects.create(
            category=policy_data['category'],
            rule=policy_data['rule'],
            priority=policy_data['priority'],
            rationale=policy_data.get('rationale', ''),
            examples=policy_data.get('examples', []),
            evidence_count=1,
            is_custom=False,
            is_active=True,
        )
```

#### 6. `backend/apps/systems/serializers_feedback.py`
**Updates:**
```python
class AIResponseFeedbackSerializer(serializers.ModelSerializer):
    class Meta:
        model = AIResponseFeedback
        fields = [
            'id', 'query', 'mode', 'response_data',
            'conversation_context', 'rating', 'feedback_text',
            'has_policy', 'policy_generated_at',  # NEW FIELDS
            'created_at', 'user_id'
        ]
        read_only_fields = ['has_policy', 'policy_generated_at']
```

---

### Frontend Files

#### 1. `frontend/src/components/AIAssistant.tsx`
**Function**: `handleFeedbackSubmit()`
**Changes:**
```typescript
const handleFeedbackSubmit = async () => {
  try {
    const response = await submitAIFeedback({
      query: currentQuery,
      mode: mode,
      response_data: currentResponse,
      rating: feedbackRating,
      feedback_text: feedbackText,
    });

    // Show different message based on auto-generation
    if (response.auto_generate_triggered) {
      message.success('‚úÖ ƒê√£ ghi nh·∫≠n ph·∫£n h·ªìi v√† t·∫°o gi·∫£i ph√°p t·ª± ƒë·ªông');
    } else {
      message.success('‚úÖ C·∫£m ∆°n ph·∫£n h·ªìi c·ªßa b·∫°n');
    }

    setFeedbackModalVisible(false);
    setFeedbackText('');
  } catch (error) {
    message.error('L·ªói g·ª≠i ph·∫£n h·ªìi');
  }
};
```

#### 2. `frontend/src/pages/AIFeedbackPolicies.tsx`
**Updates:**
- Keep "T·ª± ƒë·ªông t·∫°o gi·∫£i ph√°p" button for manual batch regeneration
- Add indicator showing which feedbacks have policies generated
- Display `policy_generated_at` timestamp

---

## üß™ Test Cases

### Test 1: Auto-Generation on Negative Feedback
```
1. User submits negative feedback via AI Assistant
2. VERIFY: API returns auto_generate_triggered=true
3. VERIFY: Async task triggered (check Celery logs)
4. Wait 5 seconds
5. VERIFY: feedback.has_policy = True
6. VERIFY: New policy exists in ImprovementPolicy table
7. VERIFY: Policy contains correct mappings from feedback
```

### Test 2: Deduplication Logic
```
1. Submit negative feedback about "user" column mapping
2. VERIFY: Policy generated
3. Submit ANOTHER negative feedback about same "user" column issue
4. VERIFY: No duplicate policy created
5. VERIFY: Original policy evidence_count unchanged (or incremented if we implement that)
```

### Test 3: Existing Policy Check
```
Setup: Create policy "Map user ‚Üí total_users"
1. Submit feedback about user column issue
2. VERIFY: AI Analyzer detects duplicate
3. VERIFY: policy_data['skip'] = true
4. VERIFY: No new policy created
```

### Test 4: Manual Regeneration Still Works
```
1. Admin clicks "T·ª± ƒë·ªông t·∫°o gi·∫£i ph√°p" button
2. VERIFY: All negative feedbacks processed
3. VERIFY: Policies regenerated/updated
4. VERIFY: All feedbacks have has_policy=True
```

### Test 5: "1.000 User" Test Case
```
Follow: 08-backlog-plan/TEST_POLICY_GENERATION_1000_USERS.md

1. Query: "Bao nhi√™u h·ªá th·ªëng c√≥ tr√™n 1.000 user?"
2. AI answers wrong (0 systems)
3. User rates negative with detailed feedback
4. VERIFY: Policy auto-generated
5. Query again same question
6. VERIFY: AI now answers correctly (3 systems)
```

---

## üìä Success Metrics

### Immediate (Technical)
- ‚úÖ 100% of negative feedbacks trigger policy generation
- ‚úÖ < 5 seconds for policy generation to complete
- ‚úÖ 0 duplicate policies created
- ‚úÖ Policies contain correct schema mappings

### Short-term (1 week)
- ‚úÖ AI accuracy improves on previously failed queries
- ‚úÖ 80%+ of similar questions answered correctly after policy
- ‚úÖ Negative feedback rate decreases

### Long-term (1 month)
- ‚úÖ Self-improving system observable
- ‚úÖ Policy database grows with domain knowledge
- ‚úÖ 90%+ user satisfaction

---

## üöÄ Implementation Order

### Sprint 1: Backend Core (Priority: P0)
**Duration**: 2-3 days

1. ‚úÖ Add `has_policy` field + migration
2. ‚úÖ Create PolicyGenerator class
3. ‚úÖ Build AI analysis prompt
4. ‚úÖ Implement context extraction
5. ‚úÖ Create Celery task
6. ‚úÖ Update feedback submission endpoint
7. ‚úÖ Test with sample feedback

### Sprint 2: Deduplication & Refinement (Priority: P1)
**Duration**: 1-2 days

1. ‚úÖ Add existing policy retrieval
2. ‚úÖ Implement duplicate detection logic
3. ‚úÖ Handle edge cases (complementary vs duplicate)
4. ‚úÖ Add comprehensive logging
5. ‚úÖ Write unit tests

### Sprint 3: Frontend & Integration (Priority: P1)
**Duration**: 1 day

1. ‚úÖ Update feedback submission UI
2. ‚úÖ Add status indicators
3. ‚úÖ Keep manual regenerate for admin
4. ‚úÖ Integration testing

### Sprint 4: Testing & Deployment (Priority: P0)
**Duration**: 1-2 days

1. ‚úÖ Run all test cases
2. ‚úÖ Test "1.000 user" scenario end-to-end
3. ‚úÖ Deploy to UAT
4. ‚úÖ User acceptance testing
5. ‚úÖ Deploy to Production
6. ‚úÖ Monitor for 24 hours

---

## üîß Technical Setup Required

### 1. Celery Configuration
```python
# backend/config/celery.py
from celery import Celery
import os

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')

app = Celery('backend')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()
```

### 2. Environment Variables
```bash
# .env
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
OPENAI_API_KEY=sk-...
```

### 3. Docker Compose Updates
```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  celery:
    build:
      context: ./backend
    command: celery -A config worker -l info
    depends_on:
      - redis
      - postgres
    env_file:
      - ./backend/.env
```

---

## üìù Notes

### Why Async Processing?
- Feedback submission should return immediately (< 500ms)
- Policy generation can take 2-5 seconds (AI API call)
- Async prevents blocking user experience

### Why Check Existing Policies?
- Avoid duplicate policies cluttering the system
- Keep policy list focused and high-quality
- AI performs better with concise, non-overlapping guidelines

### Why Full Context Extraction?
- AI needs to see WHAT went wrong (steps, SQL, results)
- Not just user's subjective feedback
- Objective analysis of actual behavior vs expected behavior

---

**Next Action**: Begin Phase 2 - Backend Implementation starting with database migration.

**Estimated Total Effort**: 5-7 days
**Risk Level**: Medium (depends on AI analysis quality)
**Dependencies**: Celery, Redis, OpenAI API
