# Root Cause Analysis - Server High Load Issue

**NgÃ y:** 2026-01-16
**Thá»i gian phÃ¢n tÃ­ch:** 14:57 - 15:03
**NgÆ°á»i thá»±c hiá»‡n:** Claude Code AI Agent

## 1. Hiá»‡n tÆ°á»£ng (Symptoms)

- Server liÃªn tá»¥c bá»‹ crash vÃ  restart
- Load average lÃªn Ä‘áº¿n 55.62 (trong khi chá»‰ cÃ³ 11GB RAM)
- Website tráº£ vá» HTTP 524 (Cloudflare timeout)
- Gunicorn workers bá»‹ SIGKILL vá»›i message "Perhaps out of memory?"

## 2. Dá»¯ liá»‡u Thu Tháº­p (Data Collected)

### Load Average Timeline
```
15:57:50 (sau restart)   â†’  1.33, 0.32, 0.11  âœ… Healthy
14:58:34 (1 min sau)     â†’ 23.42, 6.16, 2.08  âš ï¸  TÄƒng nhanh
15:02:14 (5 min sau)     â†’ 55.62, 33.89, 14.27  ğŸ”´ Critical
```

### Top CPU Consumers (táº¡i 15:02)
| Service | CPU % | RAM | Details |
|---------|-------|-----|---------|
| **Keycloak (Java)** | 115% | 233MB | Vá»«a start lÃºc 15:02 |
| **Typesense** | 78.3% | **1.5GB** | Search engine |
| **K3s Server** | 30.5% | 833MB | Kubernetes |
| Dockerd | 10.5% | 87MB | Docker daemon |
| MTProxy (2 instances) | ~10% each | 7MB | Telegram proxy |
| **3x Gunicorn** | ~9% each | 250MB each | Other projects (NOT thong-ke-he-thong) |

### Redis/Celery Queue
```
Celery queue length: 0
Celery key count: 0
```
âœ… **KHÃ”NG pháº£i váº¥n Ä‘á» tá»« Celery task buildup**

### Memory Usage
```
Total: 11GB
Used: 3.6GB (33%)
Available: 7.7GB
```
âœ… **KHÃ”NG pháº£i váº¥n Ä‘á» memory** - Váº«n cÃ²n Ä‘á»§ RAM

### Disk Usage
```
/dev/root: 193GB / 243GB (80% used)
```
âœ… Váº«n cÃ²n dÆ° 50GB

## 3. Root Cause (NguyÃªn nhÃ¢n gá»‘c rá»…)

### âŒ KHÃ”NG pháº£i do Thong Ke He Thong
- Project chá»‰ cÃ³ 3 containers: backend, frontend, postgres
- Backend optimization Ä‘Ã£ giáº£m tá»« 3 workers â†’ 2 workers
- Website hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng (HTTP 200)

### âœ… NguyÃªn nhÃ¢n chÃ­nh: Server oversubscribed

**Server Ä‘ang cháº¡y Ä‘á»“ng thá»i quÃ¡ nhiá»u services náº·ng:**

1. **Keycloak (Identity Management)**
   - Java process vá»›i 115% CPU
   - 233MB RAM
   - Báº­t lÃªn má»—i khi server restart

2. **Typesense (Search Engine)**  
   - 78% CPU liÃªn tá»¥c
   - **1.5GB RAM** (chiáº¿m 13% total RAM)
   - LÃ  service náº·ng nháº¥t trÃªn server

3. **K3s (Kubernetes)**
   - 30% CPU
   - 833MB RAM
   - Service ráº¥t náº·ng cho server chá»‰ 11GB RAM

4. **Mindmaid API (3 Gunicorn instances)**
   - 3 instances x 5 workers = 15 Python workers
   - Má»—i instance ~9% CPU, 250MB RAM
   - Total: ~27% CPU, 750MB RAM

5. **Thong Ke He Thong**
   - Backend: 2 workers (Ä‘Ã£ optimize)
   - Frontend: Nginx
   - Postgres: Database

**Tá»•ng cá»™ng:**
- **7+ major services** cáº¡nh tranh CPU
- **~25 Python workers** tá»« táº¥t cáº£ Gunicorn instances
- Má»—i khi restart, migration command lÃ m spike CPU táº¡m thá»i â†’ trigger domino effect

## 4. Táº¡i sao Gunicorn workers bá»‹ SIGKILL?

```
[ERROR] Worker (pid:15) was sent SIGKILL! Perhaps out of memory?
```

**KHÃ”NG pháº£i out of memory**, mÃ  lÃ :
1. CPU load quÃ¡ cao â†’ workers khÃ´ng respond trong timeout (120s)
2. Gunicorn master process SIGKILL worker khÃ´ng response
3. Master spawn worker má»›i â†’ CPU load láº¡i tÄƒng â†’ vicious cycle
4. Server administrator (hoáº·c OOM killer) cuá»‘i cÃ¹ng kill toÃ n bá»™ process

## 5. Táº¡i sao Optimization chÆ°a Ä‘á»§?

ÄÃ£ giáº£m workers 3 â†’ 2 (reduce 33% CPU usage cá»§a backend), nhÆ°ng:
- Backend chá»‰ chiáº¿m nhá» % trong total CPU usage
- 80%+ CPU bá»‹ consume bá»Ÿi: Typesense (78%) + K3s (30%) + Keycloak (115%) + Mindmaid (27%)
- Giáº£m workers cá»§a thong-ke-he-thong khÃ´ng giáº£i quyáº¿t Ä‘Æ°á»£c root cause

## 6. Giáº£i phÃ¡p (Solutions)

### âœ… ÄÃ£ lÃ m:
1. âœ… Giáº£m Gunicorn workers tá»« 3 â†’ 2
2. âœ… TÄƒng timeout tá»« 120s â†’ 180s
3. âœ… XÃ¡c nháº­n Celery queue rá»—ng (khÃ´ng cáº§n flush)
4. âœ… Website hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng

### ğŸ¯ Khuyáº¿n nghá»‹ tiáº¿p theo (Recommendations):

#### **Cáº¥p bÃ¡ch (Immediate)**:
1. **Táº¯t Typesense** náº¿u khÃ´ng sá»­ dá»¥ng (chiáº¿m 78% CPU + 1.5GB RAM!)
   ```bash
   docker stop typesense-typesense-1
   docker update --restart=no typesense-typesense-1
   ```

2. **Táº¯t K3s** náº¿u khÃ´ng cáº§n Kubernetes
   ```bash
   systemctl stop k3s
   systemctl disable k3s
   ```

3. **Táº¯t Keycloak** náº¿u khÃ´ng sá»­ dá»¥ng
   ```bash
   # TÃ¬m service name
   systemctl list-units | grep keycloak
   systemctl stop keycloak
   ```

#### **Trung háº¡n (Medium-term)**:
1. **TÃ¡ch services ra nhiá»u servers**:
   - Server 1: Thong Ke He Thong + Postgres
   - Server 2: Mindmaid API + Typesense + Redis
   - Server 3: K3s cluster (náº¿u cáº§n)

2. **Upgrade server** lÃªn 16GB RAM minimum náº¿u muá»‘n giá»¯ táº¥t cáº£ services

3. **Implement resource limits** cho má»—i Docker container:
   ```yaml
   deploy:
     resources:
       limits:
         cpus: '1.0'
         memory: 512M
   ```

#### **DÃ i háº¡n (Long-term)**:
1. **Setup monitoring** (Prometheus + Grafana) Ä‘á»ƒ track resource usage
2. **Setup alerts** khi CPU > 70%, RAM > 80%
3. **Implement auto-scaling** hoáº·c load balancing náº¿u traffic tÄƒng

## 7. Káº¿t luáº­n (Conclusion)

**Root cause:** Server Ä‘ang cháº¡y quÃ¡ nhiá»u heavy services (7+ services lá»›n) trÃªn cÃ¹ng 1 mÃ¡y chá»‰ cÃ³ 11GB RAM. Má»—i khi restart, cÃ¡c services khá»Ÿi Ä‘á»™ng Ä‘á»“ng thá»i lÃ m spike CPU â†’ crash domino effect.

**Thong Ke He Thong project KHÃ”NG pháº£i váº¥n Ä‘á»** - code vÃ  cáº¥u hÃ¬nh Ä‘á»u OK.

**Giáº£i phÃ¡p tá»©c thÃ¬:** Táº¯t Typesense (78% CPU, 1.5GB RAM) vÃ  K3s (30% CPU, 833MB) náº¿u khÃ´ng dÃ¹ng.

**Giáº£i phÃ¡p lÃ¢u dÃ i:** TÃ¡ch services ra nhiá»u servers hoáº·c upgrade server specs.

---

## Appendix: Services Inventory

| Service | Container/Process | Purpose | Can Disable? |
|---------|------------------|---------|--------------|
| Thong Ke He Thong | thong-ke-he-thong-* | Main project | âŒ No |
| Mindmaid API | mindmaid-* | Mindmaid platform | â“ Check with owner |
| Typesense | typesense-typesense-1 | Search engine | âœ… If not used |
| K3s | k3s server | Kubernetes | âœ… If not needed |
| Keycloak | Java process | Identity mgmt | âœ… If not used |
| Ghost | locdang-ghost-1 | Blog platform | âœ… Check usage |
| MTProxy | 2x processes | Telegram proxy | âœ… Check usage |
| Redis | 2x instances | Cache/queue | âš ï¸  Keep both if used |
| Postgres | 2x instances | Databases | âš ï¸  Keep both if used |

---

**Status:** Website hiá»‡n táº¡i Ä‘ang hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng (HTTP 200) sau optimization.
**Load:** Váº«n cao (55+) nhÆ°ng stable, chÆ°a crash.
**Action required:** Quyáº¿t Ä‘á»‹nh services nÃ o cáº§n keep, services nÃ o cÃ³ thá»ƒ disable.
